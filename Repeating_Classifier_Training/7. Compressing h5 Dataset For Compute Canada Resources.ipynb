{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compressing h5 Training/Validation Dataset\n",
    "Attempting to compress the h5 dataset to allow for temporary storage of dataset on Compute Canada Cedar GPU node SSD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import random\n",
    "import h5py\n",
    "from collections import Counter\n",
    "from progressbar import *\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "# Add the path to the parent directory to augment search for module\n",
    "par_dir = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "\n",
    "if par_dir not in sys.path:\n",
    "    sys.path.append(par_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainval_path = '/fast_scratch/WatChMaL/data/IWCDmPMT_4pi_fulltank_9M_splits_CNN'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load h5 trainval file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import test events from h5 file\n",
    "index_file = os.path.join(trainval_path,\"IWCDmPMT_4pi_fulltank_9M_trainval_idxs.npz\")\n",
    "indices = np.load(index_file, allow_pickle=True)\n",
    "train_indices = indices['train_idxs']\n",
    "val_indices = indices['val_idxs']\n",
    "\n",
    "original_data_path = os.path.join(trainval_path,\"IWCDmPMT_4pi_fulltank_9M_trainval.h5\")\n",
    "f = h5py.File(original_data_path, \"r\")\n",
    "\n",
    "hdf5_event_data = (f[\"event_data\"])\n",
    "original_eventdata = np.memmap(original_data_path, mode=\"r\", shape=hdf5_event_data.shape,\n",
    "                                    offset=hdf5_event_data.id.get_offset(), dtype=hdf5_event_data.dtype)\n",
    "\n",
    "original_eventids = np.array(f['event_ids'])\n",
    "original_energies = np.array(f['energies'])\n",
    "original_positions = np.array(f['positions'])\n",
    "original_angles = np.array(f['angles'])\n",
    "original_labels = np.array(f['labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create new compressed files, add all datasets that are small enough to load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_h5 = h5py.File(os.path.join(trainval_path,'IWCDmPMT_4pi_fulltank_9M_trainval_compressed.h5'),'w')\n",
    "\n",
    "compressed_h5.create_dataset('event_ids', data=original_eventids, compression=\"gzip\")\n",
    "compressed_h5.create_dataset('energies', data=original_energies, compression=\"gzip\")\n",
    "compressed_h5.create_dataset('positions', data=original_positions, compression=\"gzip\")\n",
    "compressed_h5.create_dataset('angles', data=original_angles, compression=\"gzip\")\n",
    "compressed_h5.create_dataset('labels', data=original_labels, compression=\"gzip\")\n",
    "compressed_h5.create_dataset('event_data', shape=(5026528, 40, 40, 38),\n",
    "                                              chunks=(1,40,40,38),\n",
    "                                              compression=\"gzip\")\n",
    "compressed_h5.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in event data in batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Unable to open object (object 'event_data' doesn't exist)\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-ce253b4bc2d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcompressed_h5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainval_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'IWCDmPMT_4pi_fulltank_9M_trainval_compressed.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mevent_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompressed_h5\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'event_data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0meof\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfirst_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlast_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1024\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/h5py/_hl/group.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    262\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid HDF5 object reference\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m             \u001b[0moid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5o\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_e\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0motype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5i\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5o.pyx\u001b[0m in \u001b[0;36mh5py.h5o.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"Unable to open object (object 'event_data' doesn't exist)\""
     ]
    }
   ],
   "source": [
    "compressed_h5 = h5py.File(os.path.join(trainval_path,'IWCDmPMT_4pi_fulltank_9M_trainval_compressed.h5'),'w')\n",
    "event_data = compressed_h5['event_data']\n",
    "eof = False\n",
    "first_idx = 0\n",
    "last_idx = 1024\n",
    "eof_index = hdf5_event_data.shape[0] - 1\n",
    "pbar = ProgressBar(widgets=['Arranging FiTQun Data. Progress: ', Percentage(), ' ', Bar(marker='0',left='[',right=']'),\n",
    "           ' ', ETA()], maxval=len(sfiltered_rootfiles))\n",
    "pbar.start()\n",
    "while not eof:\n",
    "    pbar.update(first_idx)\n",
    "    minibatch = hdf5_event_data[first_idx:last_idx]\n",
    "    event_data[first_idx:last_idx] = minibatch\n",
    "    first_idx = first_idx + 1024 + 1\n",
    "    if last_idx > eof_index - 1025:\n",
    "        eof = True\n",
    "        last_idx = eof_index\n",
    "    else:\n",
    "        last_idx = last_idx + 1024 + 1\n",
    "pbar.finish()\n",
    "compressed_h5.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_h5.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_h5 = h5py.File(os.path.join(trainval_path,'IWCDmPMT_4pi_fulltank_9M_trainval_compressed.h5'),'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
