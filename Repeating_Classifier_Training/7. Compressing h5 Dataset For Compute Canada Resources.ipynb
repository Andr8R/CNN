{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compressing h5 Training/Validation Dataset\n",
    "Attempting to compress the h5 dataset to allow for temporary storage of dataset on Compute Canada Cedar GPU node SSD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import random\n",
    "import h5py\n",
    "from collections import Counter\n",
    "from progressbar import *\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "# Add the path to the parent directory to augment search for module\n",
    "par_dir = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "\n",
    "if par_dir not in sys.path:\n",
    "    sys.path.append(par_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainval_path = '/fast_scratch/WatChMaL/data/IWCDmPMT_4pi_fulltank_9M_splits_CNN'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load h5 trainval file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import test events from h5 file\n",
    "index_file = os.path.join(trainval_path,\"IWCDmPMT_4pi_fulltank_9M_trainval_idxs.npz\")\n",
    "indices = np.load(index_file, allow_pickle=True)\n",
    "train_indices = indices['train_idxs']\n",
    "val_indices = indices['val_idxs']\n",
    "\n",
    "original_data_path = os.path.join(trainval_path,\"IWCDmPMT_4pi_fulltank_9M_trainval.h5\")\n",
    "f = h5py.File(original_data_path, \"r\")\n",
    "\n",
    "hdf5_event_data = (f[\"event_data\"])\n",
    "original_eventdata = np.memmap(original_data_path, mode=\"r\", shape=hdf5_event_data.shape,\n",
    "                                    offset=hdf5_event_data.id.get_offset(), dtype=hdf5_event_data.dtype)\n",
    "\n",
    "original_eventids = np.array(f['event_ids'])\n",
    "original_energies = np.array(f['energies'])\n",
    "original_positions = np.array(f['positions'])\n",
    "original_angles = np.array(f['angles'])\n",
    "original_labels = np.array(f['labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create new compressed files, add all datasets that are small enough to load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"event_data\": shape (5026528, 40, 40, 38), type \"<f4\">"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compressed_h5 = h5py.File(os.path.join(trainval_path,'IWCDmPMT_4pi_fulltank_9M_trainval_compressed.h5'),'w')\n",
    "\n",
    "compressed_h5.create_dataset('event_ids', data=original_eventids, compression=\"gzip\")\n",
    "compressed_h5.create_dataset('energies', data=original_energies, compression=\"gzip\")\n",
    "compressed_h5.create_dataset('positions', data=original_positions, compression=\"gzip\")\n",
    "compressed_h5.create_dataset('angles', data=original_angles, compression=\"gzip\")\n",
    "compressed_h5.create_dataset('labels', data=original_labels, compression=\"gzip\")\n",
    "compressed_h5.create_dataset('event_data', shape=(5026528, 40, 40, 38),\n",
    "                                              chunks=(1,40,40,38),\n",
    "                                              compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in event data in batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'value' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-e954376a5ba7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0meof_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhdf5_event_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m pbar = ProgressBar(widgets=['Compressing h5. Progress: ', Percentage(), ' ', Bar(marker='0',left='[',right=']'),\n\u001b[0;32m----> 8\u001b[0;31m            ' ', ETA(),Counter('Counter: {}.2f'.format(value))], maxval=original_eventdata.shape[0])\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mpbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0meof\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'value' is not defined"
     ]
    }
   ],
   "source": [
    "# compressed_h5 = h5py.File(os.path.join(trainval_path,'IWCDmPMT_4pi_fulltank_9M_trainval_compressed.h5'),'w')\n",
    "event_data = compressed_h5['event_data']\n",
    "eof = False\n",
    "first_idx = 0\n",
    "last_idx = 1024\n",
    "eof_index = hdf5_event_data.shape[0] - 1\n",
    "pbar = ProgressBar(widgets=['Compressing h5. Progress: ', Percentage(), ' ', Bar(marker='0',left='[',right=']'),\n",
    "           ' ', ETA()], maxval=original_eventdata.shape[0])\n",
    "pbar.start()\n",
    "while not eof:\n",
    "    pbar.update(first_idx)\n",
    "    minibatch = hdf5_event_data[first_idx:last_idx]\n",
    "    event_data[first_idx:last_idx] = minibatch\n",
    "    first_idx = first_idx + 1024 + 1\n",
    "    if last_idx > eof_index - 1025:\n",
    "        eof = True\n",
    "        last_idx = eof_index\n",
    "    else:\n",
    "        last_idx = last_idx + 1024 + 1\n",
    "pbar.finish()\n",
    "compressed_h5.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_h5.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_h5 = h5py.File(os.path.join(trainval_path,'IWCDmPMT_4pi_fulltank_9M_trainval_compressed.h5'),'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0/1'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"{}/{}\".format(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
