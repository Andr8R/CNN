{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import random\n",
    "import h5py\n",
    "from collections import Counter\n",
    "from progressbar import *\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "# Add the path to the parent directory to augment search for module\n",
    "par_dir = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "\n",
    "if par_dir not in sys.path:\n",
    "    sys.path.append(par_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary mapping the ordinal labels to particle types \n",
    "LABEL_DICT = {0:\"gamma\", 1:\"e\", 2:\"mu\"}\n",
    "\n",
    "# Fix the colour scheme for each particle type\n",
    "COLOR_DICT = {\"gamma\":\"red\", \"e\":\"blue\", \"mu\":\"green\"}\n",
    "\n",
    "npz_path = os.path.join(os.getcwd(), 'Index_Storage')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load ResNet output - Update the test dump location if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fprs = []\n",
    "tprs = []\n",
    "thresholds = []\n",
    "\n",
    "run_id = \"/20200511_151728\"\n",
    "\n",
    "dump_dir = \"/home/cmacdonald/CNN/dumps\"\n",
    "dump_file = \"/test_validation_iteration_dump.npz\"\n",
    "\n",
    "softmax_index_dict = {value:key for key, value in LABEL_DICT.items()}\n",
    "    \n",
    "test_dump_path = dump_dir + run_id + dump_file\n",
    "test_dump_np = np.load(test_dump_path, allow_pickle=True)\n",
    "\n",
    "res_predictedlabels = np.concatenate(list([batch_array for batch_array in test_dump_np['predicted_labels']]))\n",
    "res_softmaxes  = np.concatenate(list([batch_array for batch_array in test_dump_np['softmax']]))\n",
    "res_labels   = np.concatenate(list([batch_array for batch_array in test_dump_np['labels']]))\n",
    "res_energies = np.concatenate(list([batch_array for batch_array in test_dump_np['energies']]))\n",
    "res_rootfiles = np.concatenate(list([batch_array for batch_array in test_dump_np['rootfiles']]))\n",
    "res_eventids = np.concatenate(list([batch_array for batch_array in test_dump_np['eventids']]))\n",
    "#res_positions = test_dump_np['positions'].reshape(-1)\n",
    "res_angles = np.concatenate(list([batch_array for batch_array in test_dump_np['angles']]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load original test dataset (load full h5 and apply test indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import test events from h5 file\n",
    "filtered_index = \"/fast_scratch/WatChMaL/data/IWCD_fulltank_300_pe_idxs.npz\"\n",
    "filtered_indices = np.load(filtered_index, allow_pickle=True)\n",
    "test_filtered_indices = filtered_indices['test_idxs']\n",
    "\n",
    "original_data_path = \"/data/WatChMaL/data/IWCDmPMT_4pi_fulltank_9M.h5\"\n",
    "f = h5py.File(original_data_path, \"r\")\n",
    "\n",
    "hdf5_event_data = (f[\"event_data\"])\n",
    "original_eventdata = np.memmap(original_data_path, mode=\"r\", shape=hdf5_event_data.shape,\n",
    "                                    offset=hdf5_event_data.id.get_offset(), dtype=hdf5_event_data.dtype)\n",
    "\n",
    "original_eventids = np.array(f['event_ids'])\n",
    "original_rootfiles = np.array(f['root_files'])\n",
    "original_energies = np.array(f['energies'])\n",
    "original_positions = np.array(f['positions'])\n",
    "original_angles = np.array(f['angles'])\n",
    "original_labels = np.array(f['labels'])\n",
    "#filtered_eventdata = original_eventdata[test_filtered_indices]\n",
    "filtered_eventids = original_eventids[test_filtered_indices]\n",
    "filtered_rootfiles = original_rootfiles[test_filtered_indices]\n",
    "filtered_energies = original_energies[test_filtered_indices]\n",
    "filtered_positions = original_positions[test_filtered_indices]\n",
    "filtered_angles = original_angles[test_filtered_indices]\n",
    "filtered_labels = original_labels[test_filtered_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that resnet data is in the same order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success! Resnet output in same order as h5 test set\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(res_eventids)): \n",
    "    assert res_eventids[i]==filtered_eventids[i]\n",
    "    assert res_rootfiles[i]==filtered_rootfiles[i]\n",
    "assert len(res_eventids) == len(filtered_eventids)\n",
    "print(\"Success! Resnet output in same order as h5 test set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter out the events that FiTQun failed on from the h5 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fq_failed_idxs = np.load(os.path.join(npz_path,'fq_failed_idxs.npz'), allow_pickle = True)['failed_indices_pointing_to_h5_test_set']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: using a non-integer array as obj in delete will result in an error in the future\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:2: DeprecationWarning: using a non-integer array as obj in delete will result in an error in the future\n",
      "  \n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:3: DeprecationWarning: using a non-integer array as obj in delete will result in an error in the future\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:4: DeprecationWarning: using a non-integer array as obj in delete will result in an error in the future\n",
      "  after removing the cwd from sys.path.\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:5: DeprecationWarning: using a non-integer array as obj in delete will result in an error in the future\n",
      "  \"\"\"\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:6: DeprecationWarning: using a non-integer array as obj in delete will result in an error in the future\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "sfiltered_eventids = np.delete(filtered_eventids, fq_failed_idxs)\n",
    "sfiltered_rootfiles = np.delete(filtered_rootfiles , fq_failed_idxs)\n",
    "sfiltered_energies = np.delete(filtered_energies, fq_failed_idxs)\n",
    "sfiltered_positions = np.delete(filtered_positions, fq_failed_idxs)\n",
    "sfiltered_angles = np.delete(filtered_angles, fq_failed_idxs,0)\n",
    "sfiltered_labels = np.delete(filtered_labels, fq_failed_idxs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the fiTQun output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths for fiTQun results\n",
    "fiTQun_e_path = \"/fast_scratch/WatChMaL/data/IWCDmPMT_4pi_fulltank_fiTQun_e-.npz\"\n",
    "fiTQun_mu_path = \"/fast_scratch/WatChMaL/data/IWCDmPMT_4pi_fulltank_fiTQun_mu-.npz\"\n",
    "fiTQun_gamma_path = \"/fast_scratch/WatChMaL/data/IWCDmPMT_4pi_fulltank_fiTQun_gamma.npz\"\n",
    "\n",
    "# Load fiTQun results\n",
    "f_e = np.load(fiTQun_e_path, allow_pickle=True)\n",
    "f_mu = np.load(fiTQun_mu_path, allow_pickle=True)\n",
    "f_gamma = np.load(fiTQun_gamma_path, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's construct the FiTQun data in the same order as the h5 test set and ResNet output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "fq_filename_original = (f_gamma['filename'],f_e['filename'],f_mu['filename'])\n",
    "fq_eventids_original = ( f_gamma['eventid'],f_e['eventid'], f_mu['eventid'])\n",
    "fq_flag_original = (f_gamma['flag'] ,f_e['flag'],f_mu['flag'])\n",
    "fq_nll_original = (f_gamma['nLL'],f_e['nLL'],f_mu['nLL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Arranging FiTQun Data. Progress: 100% [0000000000000000000000000] Time: 0:00:18\n"
     ]
    }
   ],
   "source": [
    "fq_rootfiles = np.empty(len(sfiltered_rootfiles),dtype=object)\n",
    "fq_eventids = np.zeros(len(sfiltered_rootfiles))\n",
    "fq_flag = np.empty((len(sfiltered_rootfiles),2))\n",
    "fq_nll = np.empty((len(sfiltered_rootfiles),2))\n",
    "\n",
    "fq_mapping_indices = np.load(os.path.join(npz_path,'fq_mapping_idxs.npz'),allow_pickle=True)['arr_0']\n",
    "\n",
    "pbar = ProgressBar(widgets=['Arranging FiTQun Data. Progress: ', Percentage(), ' ', Bar(marker='0',left='[',right=']'),\n",
    "           ' ', ETA()], maxval=len(sfiltered_rootfiles))\n",
    "pbar.start()\n",
    "for i,ptype in enumerate(sfiltered_labels):\n",
    "    fq_rootfiles[i] = str(fq_filename_original[ptype][fq_mapping_indices[i]])\n",
    "    fq_eventids[i] = fq_eventids_original[ptype][fq_mapping_indices[i]]\n",
    "    fq_flag[i] = fq_flag_original[ptype][fq_mapping_indices[i]]\n",
    "    fq_nll[i] = fq_nll_original[ptype][fq_mapping_indices[i]]\n",
    "    pbar.update(i)\n",
    "pbar.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's again verify that the events are in the right order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Verification Progress: 100% [00000000000000000000000000000000000] Time: 0:00:24\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success! We now have a FiTQun output set in the same order as the h5 test set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pbar = ProgressBar(widgets=['Verification Progress: ', Percentage(), ' ', Bar(marker='0',left='[',right=']'),\n",
    "           ' ', ETA()], maxval=len(sfiltered_rootfiles))\n",
    "pbar.start()\n",
    "for i in range(len(sfiltered_rootfiles)):\n",
    "    assert re.sub('_fiTQun','',fq_rootfiles[i].split('/')[-1]) == sfiltered_rootfiles[i].split('/')[-1], print(fq_rootfiles[i])\n",
    "    assert fq_eventids[i] -1 == sfiltered_eventids[i]\n",
    "    pbar.update(i)\n",
    "pbar.finish()\n",
    "print(\"Success! We now have a FiTQun output set in the same order as the h5 test set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the indices of flagged events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "flagged_idxs = np.where((fq_flag[:,0] == 1.) | (fq_flag[:,1] == 1.))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The fraction of events that were flagged is 0.2193331384406174\n"
     ]
    }
   ],
   "source": [
    "print(\"The fraction of events that were flagged is \" + str(len(flagged_idxs)/len(fq_flag)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter out first FiTQun failed files, and then FiTQun flagged files, from ResNet output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:3: DeprecationWarning: using a non-integer array as obj in delete will result in an error in the future\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:4: DeprecationWarning: using a non-integer array as obj in delete will result in an error in the future\n",
      "  after removing the cwd from sys.path.\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:5: DeprecationWarning: using a non-integer array as obj in delete will result in an error in the future\n",
      "  \"\"\"\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:6: DeprecationWarning: using a non-integer array as obj in delete will result in an error in the future\n",
      "  \n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:7: DeprecationWarning: using a non-integer array as obj in delete will result in an error in the future\n",
      "  import sys\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:8: DeprecationWarning: using a non-integer array as obj in delete will result in an error in the future\n",
      "  \n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:9: DeprecationWarning: using a non-integer array as obj in delete will result in an error in the future\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "fq_failed_idxs = np.load(os.path.join(npz_path,'fq_failed_idxs.npz'),allow_pickle=True)['failed_indices_pointing_to_h5_test_set']\n",
    "\n",
    "res_filtered_predictedlabels =  np.delete(res_predictedlabels, fq_failed_idxs)\n",
    "res_filtered_softmaxes  = np.delete(res_softmaxes,fq_failed_idxs,0)\n",
    "res_filtered_labels   = np.delete(res_labels,fq_failed_idxs)\n",
    "res_filtered_energies =  np.delete(res_energies,fq_failed_idxs)\n",
    "res_filtered_rootfiles =  np.delete(res_rootfiles,fq_failed_idxs)\n",
    "res_filtered_eventids =  np.delete(res_eventids,fq_failed_idxs)\n",
    "res_filtered_angles =  np.delete(res_angles,fq_failed_idxs,0)\n",
    "\n",
    "res_filtered_predictedlabels =  np.delete(res_filtered_predictedlabels,flagged_idxs)\n",
    "res_filtered_softmaxes  = np.delete(res_filtered_softmaxes,flagged_idxs,0)\n",
    "res_filtered_labels   = np.delete(res_filtered_labels,flagged_idxs)\n",
    "res_filtered_energies =  np.delete(res_filtered_energies,flagged_idxs)\n",
    "res_filtered_rootfiles =  np.delete(res_filtered_rootfiles,flagged_idxs)\n",
    "res_filtered_eventids =  np.delete(res_filtered_eventids,flagged_idxs)\n",
    "res_filtered_angles =  np.delete(res_filtered_angles,flagged_idxs,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do a sanity check comparing unflagged FQ events with our filtered ResNet output size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2614337"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(fq_filename_original[0].shape[0] + fq_filename_original[1].shape[0] + fq_filename_original[2].shape[0] ) - len(flagged_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success! Resnet output size matches size of unflagged, successful FiTQun output\n"
     ]
    }
   ],
   "source": [
    "for data in (res_filtered_softmaxes, res_filtered_predictedlabels, res_filtered_labels, res_filtered_energies, res_filtered_rootfiles, res_filtered_eventids, res_filtered_angles):\n",
    "    assert data.shape[0] == 2614337\n",
    "print(\"Success! Resnet output size matches size of unflagged, successful FiTQun output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(os.path.join(os.getcwd(),'resnet_filtered_output.npz'), res_filtered_softmaxes=res_filtered_softmaxes,\n",
    "                                                                 res_filtered_rootfiles=res_filtered_rootfiles,\n",
    "                                                                 res_filtered_eventids=res_filtered_eventids,\n",
    "                                                                 res_filtered_energies=res_filtered_energies,\n",
    "                                                                 res_filtered_labels=res_filtered_labels,\n",
    "                                                                 res_filtered_predictedlabels=res_filtered_predictedlabels,\n",
    "                                                                 res_filtered_angles=res_filtered_angles\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
