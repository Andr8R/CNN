{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Compressing h5 Training/Validation Dataset\n",
    "Attempting to compress the h5 dataset to allow for temporary storage of dataset on Compute Canada Cedar GPU node SSD. Compression was done using create_compressed_h5.py in the same directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import random\n",
    "import h5py\n",
    "from collections import Counter\n",
    "from progressbar import *\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "# Add the path to the parent directory to augment search for module\n",
    "par_dir = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "\n",
    "if par_dir not in sys.path:\n",
    "    sys.path.append(par_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainval_path = '/fast_scratch/WatChMaL/data/IWCDmPMT_4pi_fulltank_9M_splits_CNN'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load h5 trainval file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import test events from h5 file\n",
    "index_file = os.path.join(trainval_path,\"IWCDmPMT_4pi_fulltank_9M_trainval_idxs.npz\")\n",
    "indices = np.load(index_file, allow_pickle=True)\n",
    "train_indices = indices['train_idxs']\n",
    "val_indices = indices['val_idxs']\n",
    "\n",
    "original_data_path = os.path.join(trainval_path,\"IWCDmPMT_4pi_fulltank_9M_trainval.h5\")\n",
    "f = h5py.File(original_data_path, \"r\")\n",
    "\n",
    "hdf5_event_data = (f[\"event_data\"])\n",
    "# original_eventdata = np.memmap(original_data_path, mode=\"r\", shape=hdf5_event_data.shape,\n",
    "#                                     offset=hdf5_event_data.id.get_offset(), dtype=hdf5_event_data.dtype)\n",
    "original_eventids = np.array(f['event_ids'])\n",
    "original_energies = np.array(f['energies'])\n",
    "original_positions = np.array(f['positions'])\n",
    "original_angles = np.array(f['angles'])\n",
    "original_labels = np.array(f['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5026528, 40, 40, 38)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_eventdata.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load compressed h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_data_path = os.path.join(trainval_path,'IWCDmPMT_4pi_fulltank_9M_trainval_compressed.h5')\n",
    "\n",
    "compressed_h5 = h5py.File(compressed_data_path,'r')\n",
    "\n",
    "compressed_event_data = (f[\"event_data\"])\n",
    "compressed_eventids = np.array(compressed_h5['event_ids'])\n",
    "compressed_energies = np.array(compressed_h5['energies'])\n",
    "compressed_positions = np.array(compressed_h5['positions'])\n",
    "compressed_angles = np.array(compressed_h5['angles'])\n",
    "compressed_labels = np.array(compressed_h5['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5026528, 40, 40, 38)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compressed_event_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check that the datasets are still identical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Verification Progress: 100% [00000000000000000000000000000000000] Time: 0:40:51\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success! Compressed dataset contains the same data in the same order\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pbar = ProgressBar(widgets=['Verification Progress: ', Percentage(), ' ', Bar(marker='0',left='[',right=']'),\n",
    "           ' ', ETA()], maxval=compressed_event_data.shape[0])\n",
    "pbar.start()\n",
    "for idx in range(compressed_event_data.shape[0]):\n",
    "    pbar.update(idx)\n",
    "    assert np.array_equal(compressed_event_data[idx],original_eventdata[idx]) \n",
    "    assert compressed_eventids[idx] == original_eventids[idx] \n",
    "    assert compressed_energies[idx] == original_energies[idx] \n",
    "    assert np.array_equal(compressed_positions[idx],original_positions[idx]) \n",
    "    assert np.array_equal(compressed_angles[idx],original_angles[idx]) \n",
    "    assert compressed_labels[idx] == original_labels[idx] \n",
    "pbar.finish()\n",
    "print(\"Success! Compressed dataset contains the same data in the same order\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
