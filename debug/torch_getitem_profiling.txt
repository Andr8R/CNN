Timer unit: 1e-06 s

Total time: 0 s
File: /home/cmacdonald/CNN/io_utils/data_handling_train.py
Function: __getitem__ at line 297

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   297                                               @profile
   298                                               def __getitem__(self, index):
   299                                                   '''
   300                                                   self.a = self.event_data[self.datasets[0]][index,:,:,:19]
   301                                                   #self.c = self.a[:,:,self.endcap_mPMT_order[:,1]]
   302                                                   #self.c[12:28,:,:] = self.a[12:28,:,:19]
   303                                                   self.c = self.a
   304                                                   return np.squeeze(self.chrg_func(np.expand_dims(np.ascontiguousarray(np.transpose(self.c,[2,0,1])), axis=0), self.chrg_acc, apply=True)), self.labels[self.datasets[0]][index], self.energies[self.datasets[0]][index], self.angles[self.datasets[0]][index], index, self.positions[self.datasets[0]][index]
   305                                                   '''
   306                                                   np.random.shuffle(self.datasets)
   307                                                   for i in np.arange(len(self.datasets)):
   308                                           
   309                                                       if index < self.labels[self.datasets[i]].shape[0]:
   310                                                           self.a = self.event_data[self.datasets[i]][index,:,:,:19]
   311                                                           if self.a.shape[0] == 16:
   312                                                               self.c = np.concatenate((self.b,self.a,self.b), axis=0)
   313                                                               self.e = np.random.rand(192,19,2)
   314                                                               prob = random.randrange(1, 7, 1)/100
   315                                                               self.f = self.e[:,:,0] > prob
   316                                                               self.g = np.where(self.f, 0, self.e[:,:,1])
   317                                                               self.c[self.d[:,0], self.d[:,1]] = self.g
   318                                                               os.posix_fadvise(self.fds[i].fileno(), 0, self.filesizes[i], os.POSIX_FADV_DONTNEED)
   319                                                               # os.posix_fadvise(self.fds[i].fileno(), self.offsets[i], self.dataset_sizes[i], 
   320                                                               #                                      os.POSIX_FADV_DONTNEED)
   321                                                               return np.squeeze(self.chrg_func(np.expand_dims(np.ascontiguousarray(np.transpose(self.c,[2,0,1])),axis=0), self.chrg_acc, apply=True)), self.labels[self.datasets[i]][index], self.energies[self.datasets[i]][index], self.angles[self.datasets[i]][index], index, self.positions[self.datasets[i]][index]
   322                                           
   323                                                           else:
   324                                                               self.b[12:28,:,:] = self.a[12:28, :, :]
   325                                                               self.b[self.new_cap_ind[:,0], self.new_cap_ind[:,1],:] = self.a[self.cap_ind[:,0], self.cap_ind[:,1]]
   326                                                               self.c = self.b
   327                                                               #self.c = self.a[:,:,self.endcap_mPMT_order[:,1]]
   328                                                               #self.c[12:28,:,:] = self.a[12:28,:,:19]
   329                                                               os.posix_fadvise(self.fds[i].fileno(), 0, self.filesizes[i], os.POSIX_FADV_DONTNEED)
   330                                                               # os.posix_fadvise(self.fds[i].fileno(), self.offsets[i], self.dataset_sizes[i], 
   331                                                               #                                      os.POSIX_FADV_DONTNEED)
   332                                                               return np.squeeze(self.chrg_func(np.expand_dims(np.ascontiguousarray(np.transpose(self.c,[2,0,1])), axis=0), self.chrg_acc, apply=True)), self.labels[self.datasets[i]][index], self.energies[self.datasets[i]][index], self.angles[self.datasets[i]][index], index, self.positions[self.datasets[i]][index]
   333                                                   assert False, "empty batch"
   334                                                   raise RuntimeError("empty batch")

Total time: 0 s
File: /home/cmacdonald/CNN/io_utils/data_handling_train.py
Function: run_test at line 342

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   342                                           @profile
   343                                           def run_test():
   344                                               train_dset = WCH5DatasetT(trainval_path, trainval_idxs, norm_params_path, chrg_norm, time_norm, shuffle=shuffle, num_datasets=num_datasets, trainval_subset=trainval_subset)
   345                                               train_indices = [i for i in range(len(train_dset))]
   346                                               
   347                                               for epoch in range(2):
   348                                                   indices_left = train_indices
   349                                                   i = 0
   350                                                   while len(indices_left) > 0:
   351                                                       batch_idxs = indices_left[0:512 if len(indices_left) >= 512 else len(indices_left)]
   352                                                       assert len(batch_idxs) == 512
   353                                                       data = fetch_batch(train_dset,batch_idxs)
   354                                                       indices_left = np.delete(indices_left, range(512 if len(indices_left) >= 512 else len(indices_left)))
   355                                                       print("Epoch: {} Batch: {} ".format(epoch+1,i+1))
   356                                                       i+=1

Total time: 0 s
File: /home/cmacdonald/CNN/io_utils/data_handling_train.py
Function: fetch_batch at line 357

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   357                                           @profile
   358                                           def fetch_batch(dset, batch_idxs):
   359                                               data = []
   360                                               for idx in batch_idxs:
   361                                                   data.append(dset[idx])
   362                                               return data

Total time: 118.273 s
File: test_watchmal_dset.py
Function: run_test at line 30

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    30                                           @profile
    31                                           def run_test(args):
    32         1          2.0      2.0      0.0      train_dset = WCH5DatasetT(trainval_path, trainval_idxs, norm_params_path, chrg_norm, time_norm,
    33         1     508230.0 508230.0      0.4                                              shuffle=shuffle, num_datasets=num_datasets, trainval_subset=trainval_subset)
    34         1     519448.0 519448.0      0.4      train_indices = [i for i in range(len(train_dset))]
    35         1          3.0      3.0      0.0      train_loader = DataLoader(train_dset, batch_size=512, shuffle=False,
    36         1        116.0    116.0      0.0                                          pin_memory=False, sampler=SubsetRandomSampler(train_indices), num_workers=args.num_workers)
    37         1          3.0      3.0      0.0      start = time.time()
    38         1          4.0      4.0      0.0      for epoch in range(args.epochs):
    39        89  117215696.0 1317030.3     99.1          for i, data in enumerate(train_loader):
    40        88      27687.0    314.6      0.0              print(time.time() - start)
    41        88       1236.0     14.0      0.0              print("Epoch: {} Batch: {} ".format(epoch+1,i))
    42        88        157.0      1.8      0.0              start = time.time()

