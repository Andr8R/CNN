{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# July 18 - Model state dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import math\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Add the path to the parent directory to augment search for module\n",
    "par_dir = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "if par_dir not in sys.path:\n",
    "    sys.path.append(par_dir)\n",
    "    \n",
    "# Import the custom plotting module\n",
    "from plot_utils import plot_utils\n",
    "import random\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## It is observed that the model dictionary is not being loaded correctly since the validation loss with the trained model is way lower than the validation loss with the untrained model but with loaded weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the dictionary structure and see how it might be incorrecly getting loaded. Use the saved state for the AE with 64 latent dimensions trained for 10.0 epochs using 50000 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['global_step', 'optimizer', 'state_dict'])\n"
     ]
    }
   ],
   "source": [
    "weight_file = \"/home/akajal/WatChMaL/VAE/dumps/20190718_140055/ENet_latest.pth\"\n",
    "        \n",
    "# Open a file in read-binary mode\n",
    "with open(weight_file, 'rb') as f:\n",
    "\n",
    "    # torch interprets the file, then we can access using string keys\n",
    "    checkpoint = torch.load(f)\n",
    "    \n",
    "print(checkpoint.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The saved state file has three keys : global_step, optimizer, state_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First check the value of the key global_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "step = checkpoint['global_step']\n",
    "print(step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Secondly check the value of the key optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['state', 'param_groups'])\n"
     ]
    }
   ],
   "source": [
    "opt = checkpoint['optimizer']\n",
    "print(opt.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is the key-value pair concerning the optimizer which should be irrelevant for validation since no optimizer is used there"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thirdly check the value of the key state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['module.encoder.en_conv1a.weight', 'module.encoder.en_conv1a.bias', 'module.encoder.en_conv1b.weight', 'module.encoder.en_conv1b.bias', 'module.encoder.en_conv2.weight', 'module.encoder.en_conv2.bias', 'module.encoder.en_conv3a.weight', 'module.encoder.en_conv3a.bias', 'module.encoder.en_conv3b.weight', 'module.encoder.en_conv3b.bias', 'module.encoder.en_conv4.weight', 'module.encoder.en_conv4.bias', 'module.encoder.en_fc1.weight', 'module.encoder.en_fc1.bias', 'module.encoder.en_fc2.weight', 'module.encoder.en_fc2.bias', 'module.encoder.en_fc3.weight', 'module.encoder.en_fc3.bias', 'module.encoder.en_fc4.weight', 'module.encoder.en_fc4.bias', 'module.decoder.de_fc4.weight', 'module.decoder.de_fc4.bias', 'module.decoder.de_fc3.weight', 'module.decoder.de_fc3.bias', 'module.decoder.de_fc2.weight', 'module.decoder.de_fc2.bias', 'module.decoder.de_fc1.weight', 'module.decoder.de_fc1.bias', 'module.decoder.de_conv4.weight', 'module.decoder.de_conv4.bias', 'module.decoder.de_conv3b.weight', 'module.decoder.de_conv3b.bias', 'module.decoder.de_conv3a.weight', 'module.decoder.de_conv3a.bias', 'module.decoder.de_conv2.weight', 'module.decoder.de_conv2.bias', 'module.decoder.de_conv1b.weight', 'module.decoder.de_conv1b.bias', 'module.decoder.de_conv1a.weight', 'module.decoder.de_conv1a.bias'])\n"
     ]
    }
   ],
   "source": [
    "sd = checkpoint['state_dict']\n",
    "print(sd.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([64, 19, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "en_conv1a_weight = sd['module.encoder.en_conv1a.weight']\n",
    "print(type(en_conv1a_weight))\n",
    "print(en_conv1a_weight.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([64, 64, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "en_conv2_weight = sd['module.encoder.en_conv2.weight']\n",
    "print(type(en_conv2_weight))\n",
    "print(en_conv2_weight.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The above save state file was from a multi-gpu model, check the dict for a single GPU saved state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_file = \"/home/akajal/WatChMaL/VAE/dumps/20190718_140055/ENet_latest.pth\"\n",
    "        \n",
    "# Open a file in read-binary mode\n",
    "with open(weight_file, 'rb') as f:\n",
    "\n",
    "    # torch interprets the file, then we can access using string keys\n",
    "    checkpoint = torch.load(f)\n",
    "    \n",
    "print(checkpoint.keys())\n",
    "\n",
    "step = checkpoint['global_step']\n",
    "print(step)\n",
    "\n",
    "sd = checkpoint['state_dict']\n",
    "print(sd.keys())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
