{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# September 30 - M2 Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goal : Write a dummy implementation which simulates the process of the semi-supervised VAE to ensure the correctness of the tensor operations to be performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def print_tensor(in_tensor):\n",
    "    assert in_tensor is not None\n",
    "    print(in_tensor.size(), \"\\n\", in_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Unlabelled case\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assume `batch_size = 2`, `num_latent_dims=4` and `num_classes=3`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "num_latent_dims = 4\n",
    "num_classes = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4]) \n",
      " tensor([[ 0.1447, -0.2225,  1.3976,  1.7152],\n",
      "        [-0.7281, -0.3237,  1.0932, -0.1912]])\n"
     ]
    }
   ],
   "source": [
    "z_prime = torch.randn(batch_size, num_latent_dims)\n",
    "print(z_prime.size(), \"\\n\", z_prime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 4]) \n",
      " tensor([[[ 0.1447, -0.2225,  1.3976,  1.7152]],\n",
      "\n",
      "        [[-0.7281, -0.3237,  1.0932, -0.1912]]])\n"
     ]
    }
   ],
   "source": [
    "z_prime = z_prime.view(-1, 1, z_prime.size(1))\n",
    "print(z_prime.size(), \"\\n\", z_prime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 4]) \n",
      " tensor([[[ 0.1447, -0.2225,  1.3976,  1.7152],\n",
      "         [ 0.1447, -0.2225,  1.3976,  1.7152],\n",
      "         [ 0.1447, -0.2225,  1.3976,  1.7152]],\n",
      "\n",
      "        [[-0.7281, -0.3237,  1.0932, -0.1912],\n",
      "         [-0.7281, -0.3237,  1.0932, -0.1912],\n",
      "         [-0.7281, -0.3237,  1.0932, -0.1912]]])\n"
     ]
    }
   ],
   "source": [
    "z_prime = z_prime + torch.zeros(batch_size, num_classes, num_latent_dims)\n",
    "print(z_prime.size(), \"\\n\", z_prime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finished reshaping and making 3 copies of the deterministic latent vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3]) \n",
      " tensor([[1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "i_3 = torch.eye(num_classes)\n",
    "print(i_3.size(), \"\\n\", i_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 3]) \n",
      " tensor([[[1., 0., 0.],\n",
      "         [0., 1., 0.],\n",
      "         [0., 0., 1.]]])\n"
     ]
    }
   ],
   "source": [
    "i_3 = i_3.view(-1, num_classes, num_classes)\n",
    "print(i_3.size(), \"\\n\", i_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 3]) \n",
      " tensor([[[1., 0., 0.],\n",
      "         [0., 1., 0.],\n",
      "         [0., 0., 1.]],\n",
      "\n",
      "        [[1., 0., 0.],\n",
      "         [0., 1., 0.],\n",
      "         [0., 0., 1.]]])\n"
     ]
    }
   ],
   "source": [
    "i_3 = i_3 + torch.zeros(batch_size, num_classes, num_classes)\n",
    "print(i_3.size(), \"\\n\", i_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finished initializing the one-hot vectors for each of the three classes as an identity and reshaping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate the two tensor at the latest dimension to construct the z_prime + y tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 7]) \n",
      " tensor([[[ 0.1447, -0.2225,  1.3976,  1.7152,  1.0000,  0.0000,  0.0000],\n",
      "         [ 0.1447, -0.2225,  1.3976,  1.7152,  0.0000,  1.0000,  0.0000],\n",
      "         [ 0.1447, -0.2225,  1.3976,  1.7152,  0.0000,  0.0000,  1.0000]],\n",
      "\n",
      "        [[-0.7281, -0.3237,  1.0932, -0.1912,  1.0000,  0.0000,  0.0000],\n",
      "         [-0.7281, -0.3237,  1.0932, -0.1912,  0.0000,  1.0000,  0.0000],\n",
      "         [-0.7281, -0.3237,  1.0932, -0.1912,  0.0000,  0.0000,  1.0000]]])\n"
     ]
    }
   ],
   "source": [
    "z_prime_y = torch.cat((z_prime, i_3), dim=2)\n",
    "print(z_prime_y.size(), \"\\n\", z_prime_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now to use the `torch.nn.Linear` layers, collapse the 3-D tensors onto 2-D tensors where the first dimension resembles the batch dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 7]) \n",
      " tensor([[ 0.1447, -0.2225,  1.3976,  1.7152,  1.0000,  0.0000,  0.0000],\n",
      "        [ 0.1447, -0.2225,  1.3976,  1.7152,  0.0000,  1.0000,  0.0000],\n",
      "        [ 0.1447, -0.2225,  1.3976,  1.7152,  0.0000,  0.0000,  1.0000],\n",
      "        [-0.7281, -0.3237,  1.0932, -0.1912,  1.0000,  0.0000,  0.0000],\n",
      "        [-0.7281, -0.3237,  1.0932, -0.1912,  0.0000,  1.0000,  0.0000],\n",
      "        [-0.7281, -0.3237,  1.0932, -0.1912,  0.0000,  0.0000,  1.0000]])\n"
     ]
    }
   ],
   "source": [
    "z_prime_y = z_prime_y.view(-1, num_latent_dims+num_classes)\n",
    "print(z_prime_y.size(), \"\\n\", z_prime_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 4]) \n",
      " tensor([[ 0.1447, -0.2225,  1.3976,  1.7152],\n",
      "        [ 0.1447, -0.2225,  1.3976,  1.7152],\n",
      "        [ 0.1447, -0.2225,  1.3976,  1.7152],\n",
      "        [-0.7281, -0.3237,  1.0932, -0.1912],\n",
      "        [-0.7281, -0.3237,  1.0932, -0.1912],\n",
      "        [-0.7281, -0.3237,  1.0932, -0.1912]])\n"
     ]
    }
   ],
   "source": [
    "z_prime_collapsed = z_prime.view(-1, num_latent_dims)\n",
    "print(z_prime_collapsed.size(), \"\\n\", z_prime_collapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define and apply the reparameterization layers corresponding to the new dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = torch.nn.Linear(num_latent_dims+num_classes, num_latent_dims)\n",
    "logvar = torch.nn.Linear(num_latent_dims, num_latent_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 4]) \n",
      " tensor([[-0.0693,  0.0369,  0.8561,  1.0006],\n",
      "        [-0.4374,  0.0777,  0.7816,  1.0024],\n",
      "        [-0.3745, -0.0354,  0.6796,  1.0796],\n",
      "        [ 0.2304, -0.1905,  0.4715,  0.6405],\n",
      "        [-0.1378, -0.1498,  0.3970,  0.6424],\n",
      "        [-0.0749, -0.2629,  0.2950,  0.7195]], grad_fn=<AddmmBackward>)\n",
      "torch.Size([6, 4]) \n",
      " tensor([[-0.9302, -1.0325, -0.3666, -0.8098],\n",
      "        [-0.9302, -1.0325, -0.3666, -0.8098],\n",
      "        [-0.9302, -1.0325, -0.3666, -0.8098],\n",
      "        [-0.5283, -0.4938, -0.7802, -0.6109],\n",
      "        [-0.5283, -0.4938, -0.7802, -0.6109],\n",
      "        [-0.5283, -0.4938, -0.7802, -0.6109]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "z_mu = mu(z_prime_y)\n",
    "z_logvar = logvar(z_prime_collapsed)\n",
    "\n",
    "print(z_mu.size(), \"\\n\", z_mu)\n",
    "print(z_logvar.size(), \"\\n\", z_logvar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reparameterization trick\n",
    "std = z_logvar.mul(0.5).exp()\n",
    "eps = std.new(std.size()).normal_()\n",
    "z = eps.mul(std).add(z_mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 4]) \n",
      " tensor([[-0.4760,  0.8756,  1.1344,  0.6945],\n",
      "        [-1.1555,  1.3650, -0.4837,  0.8919],\n",
      "        [-0.2572, -0.3965,  1.1423,  0.7819],\n",
      "        [ 0.8803,  0.2928,  0.3984,  0.2667],\n",
      "        [ 0.4242,  0.7377,  1.1044,  0.3319],\n",
      "        [ 0.5081,  0.0090,  0.9278,  0.8481]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(z.size(), \"\\n\", z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 3]) \n",
      " tensor([[[1., 0., 0.],\n",
      "         [0., 1., 0.],\n",
      "         [0., 0., 1.]],\n",
      "\n",
      "        [[1., 0., 0.],\n",
      "         [0., 1., 0.],\n",
      "         [0., 0., 1.]]])\n"
     ]
    }
   ],
   "source": [
    "print_tensor(i_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 3]) \n",
      " tensor([[1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "print_tensor(i_3.view(-1, num_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 7]) \n",
      " tensor([[-0.4760,  0.8756,  1.1344,  0.6945,  1.0000,  0.0000,  0.0000],\n",
      "        [-1.1555,  1.3650, -0.4837,  0.8919,  0.0000,  1.0000,  0.0000],\n",
      "        [-0.2572, -0.3965,  1.1423,  0.7819,  0.0000,  0.0000,  1.0000],\n",
      "        [ 0.8803,  0.2928,  0.3984,  0.2667,  1.0000,  0.0000,  0.0000],\n",
      "        [ 0.4242,  0.7377,  1.1044,  0.3319,  0.0000,  1.0000,  0.0000],\n",
      "        [ 0.5081,  0.0090,  0.9278,  0.8481,  0.0000,  0.0000,  1.0000]],\n",
      "       grad_fn=<CatBackward>)\n"
     ]
    }
   ],
   "source": [
    "z = torch.cat((z, i_3.view(-1, num_classes)), dim=1)\n",
    "print_tensor(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assue for simplicity that the decoder is just an identity, then implement the correct evaluation of the MSE loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 4]) \n",
      " tensor([[ 1.3055,  0.9925,  0.2280, -0.0165],\n",
      "        [ 0.2937,  0.5772,  1.2061,  0.9281],\n",
      "        [ 0.5168, -0.0194,  1.0562,  0.6417],\n",
      "        [-1.2945, -0.3507, -0.9659,  1.9311],\n",
      "        [-0.5934, -1.3755, -1.9839,  1.1759],\n",
      "        [-0.2052, -0.7946, -0.0683,  1.1974]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x_prime = z\n",
    "print(x_prime.size(), \"\\n\", x_prime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4]) \n",
      " tensor([[-1.0631,  0.9716, -0.3089,  2.3596],\n",
      "        [ 1.6066,  1.3053,  0.0722, -1.4586]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2,4)\n",
    "print(x.size(), \"\\n\", x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 4]) \n",
      " tensor([[[-1.0631,  0.9716, -0.3089,  2.3596],\n",
      "         [-1.0631,  0.9716, -0.3089,  2.3596],\n",
      "         [-1.0631,  0.9716, -0.3089,  2.3596]],\n",
      "\n",
      "        [[ 1.6066,  1.3053,  0.0722, -1.4586],\n",
      "         [ 1.6066,  1.3053,  0.0722, -1.4586],\n",
      "         [ 1.6066,  1.3053,  0.0722, -1.4586]]])\n"
     ]
    }
   ],
   "source": [
    "x = x.view(2,1,4) + torch.zeros(2,3,4)\n",
    "print(x.size(), \"\\n\", x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 4]) \n",
      " tensor([[-1.0631,  0.9716, -0.3089,  2.3596],\n",
      "        [-1.0631,  0.9716, -0.3089,  2.3596],\n",
      "        [-1.0631,  0.9716, -0.3089,  2.3596],\n",
      "        [ 1.6066,  1.3053,  0.0722, -1.4586],\n",
      "        [ 1.6066,  1.3053,  0.0722, -1.4586],\n",
      "        [ 1.6066,  1.3053,  0.0722, -1.4586]])\n"
     ]
    }
   ],
   "source": [
    "x = x.view(6,4)\n",
    "print(x.size(), \"\\n\", x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_loss = torch.nn.MSELoss(reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 4]) \n",
      " tensor([[5.6102e+00, 4.3468e-04, 2.8829e-01, 5.6457e+00],\n",
      "        [1.8407e+00, 1.5558e-01, 2.2951e+00, 2.0491e+00],\n",
      "        [2.4961e+00, 9.8208e-01, 1.8635e+00, 2.9509e+00],\n",
      "        [8.4165e+00, 2.7423e+00, 1.0778e+00, 1.1490e+01],\n",
      "        [4.8401e+00, 7.1869e+00, 4.2278e+00, 6.9407e+00],\n",
      "        [3.2826e+00, 4.4096e+00, 1.9733e-02, 7.0544e+00]],\n",
      "       grad_fn=<PowBackward0>)\n"
     ]
    }
   ],
   "source": [
    "mse_x_x_prime = mse_loss(x, x_prime)\n",
    "print(mse_x_x_prime.size(), \"\\n\", mse_x_x_prime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6]) \n",
      " tensor([11.5446,  6.3405,  8.2926, 23.7269, 23.1955, 14.7664],\n",
      "       grad_fn=<SumBackward2>)\n"
     ]
    }
   ],
   "source": [
    "mse_x_x_prime = torch.sum(mse_x_x_prime, dim=1)\n",
    "print(mse_x_x_prime.size(), \"\\n\", mse_x_x_prime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 1]) \n",
      " tensor([[[11.5446],\n",
      "         [ 6.3405],\n",
      "         [ 8.2926]],\n",
      "\n",
      "        [[23.7269],\n",
      "         [23.1955],\n",
      "         [14.7664]]], grad_fn=<ViewBackward>)\n"
     ]
    }
   ],
   "source": [
    "mse_x_x_prime = mse_x_x_prime.view(batch_size, num_classes, 1)\n",
    "print(mse_x_x_prime.size(), \"\\n\", mse_x_x_prime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_mse_loss = mse_x_x_prime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarility computing the KL divergence loss using the mu and logvar vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 4]) \n",
      " tensor([[ 0.1198, -0.7514, -0.3353,  0.5805],\n",
      "        [-0.3165, -0.4047, -0.2002,  0.9048],\n",
      "        [-0.0194, -0.1035, -0.4782,  0.7672],\n",
      "        [-0.2469, -0.3395, -0.6040,  0.7591],\n",
      "        [-0.6832,  0.0071, -0.4688,  1.0834],\n",
      "        [-0.3861,  0.3083, -0.7468,  0.9458]], grad_fn=<AddmmBackward>)\n",
      "torch.Size([6, 4]) \n",
      " tensor([[ 0.1019,  0.5624,  0.4668, -0.3781],\n",
      "        [ 0.1019,  0.5624,  0.4668, -0.3781],\n",
      "        [ 0.1019,  0.5624,  0.4668, -0.3781],\n",
      "        [ 0.4031,  0.0436,  0.0706,  0.0051],\n",
      "        [ 0.4031,  0.0436,  0.0706,  0.0051],\n",
      "        [ 0.4031,  0.0436,  0.0706,  0.0051]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(z_mu.size(), \"\\n\", z_mu)\n",
    "print(z_logvar.size(), \"\\n\", z_logvar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_kl_loss = -0.5 * torch.sum(1 + z_logvar - z_mu.pow(2) - z_logvar.exp(), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 1]) \n",
      " tensor([[[0.7088],\n",
      "         [0.7559],\n",
      "         [0.6088]],\n",
      "\n",
      "        [[0.6071],\n",
      "         [0.9786],\n",
      "         [0.8966]]], grad_fn=<ViewBackward>)\n"
     ]
    }
   ],
   "source": [
    "batch_kl_loss = batch_kl_loss.view(batch_size, num_classes, 1)\n",
    "print(batch_kl_loss.size(), \"\\n\", batch_kl_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add the batch MSE loss and batch KL loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_total_loss = batch_mse_loss + batch_kl_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 1]) \n",
      " tensor([[[12.2534],\n",
      "         [ 7.0964],\n",
      "         [ 8.9014]],\n",
      "\n",
      "        [[24.3340],\n",
      "         [24.1741],\n",
      "         [15.6630]]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(batch_total_loss.size(), \"\\n\", batch_total_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weight the loss terms by the corresponding $q_{\\phi}(y|x)$ for each $y \\in Y$. Assume the $\\pi_{\\phi}(x)$ vector is passed as batch_size $\\times$ num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3]) \n",
      " tensor([[ 1.1621,  0.5065, -0.5819],\n",
      "        [-0.8934,  0.9607,  1.1394]])\n"
     ]
    }
   ],
   "source": [
    "pi_x = torch.randn(batch_size, num_classes)\n",
    "print(pi_x.size(), \"\\n\", pi_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3]) \n",
      " tensor([[0.5903, 0.3065, 0.1032],\n",
      "        [0.0666, 0.4251, 0.5083]])\n"
     ]
    }
   ],
   "source": [
    "softmax = torch.nn.Softmax(dim=1)\n",
    "pi_x = softmax(pi_x)\n",
    "print(pi_x.size(), \"\\n\", pi_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 3]) \n",
      " tensor([[[0.5903, 0.3065, 0.1032]],\n",
      "\n",
      "        [[0.0666, 0.4251, 0.5083]]])\n"
     ]
    }
   ],
   "source": [
    "pi_x = pi_x.view(batch_size, 1, num_classes)\n",
    "print(pi_x.size(), \"\\n\", pi_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2]) \n",
      " tensor([10.3271, 19.8585], grad_fn=<ViewBackward>)\n"
     ]
    }
   ],
   "source": [
    "weighted_loss = torch.bmm(pi_x, batch_total_loss).view(-1)\n",
    "print(weighted_loss.size(), \"\\n\", weighted_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([]) \n",
      " tensor(15.0928, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "final_weighted_loss = torch.mean(weighted_loss)\n",
    "print(final_weighted_loss.size(), \"\\n\", final_weighted_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For the unlabelled case, need to calculate the entropy $$\\mathcal{H}(q_{\\phi}(y|x) = \\sum_{y}q_{\\phi}(y|x)logq_{\\phi}(y|x)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 3]) \n",
      " tensor([[[0.1962, 0.2579, 0.5459]],\n",
      "\n",
      "        [[0.3447, 0.4228, 0.2325]]])\n"
     ]
    }
   ],
   "source": [
    "print(pi_x.size(), \"\\n\", pi_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Entropy loss from https://discuss.pytorch.org/t/calculating-the-entropy-loss/14510"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HLoss(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(HLoss, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        b = torch.nn.functional.softmax(x, dim=1) * torch.nn.functional.log_softmax(x, dim=1)\n",
    "        print(b.size())\n",
    "        b = -1.0 * torch.sum(b, dim=1)\n",
    "        return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3]) \n",
      " tensor([[-0.3424, -0.1135, -0.8758],\n",
      "        [-0.2473,  0.7513,  1.0534]])\n"
     ]
    }
   ],
   "source": [
    "pi_x = torch.randn(batch_size, num_classes)\n",
    "print(pi_x.size(), \"\\n\", pi_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3])\n",
      "torch.Size([2]) \n",
      " tensor([1.0540, 0.9860])\n"
     ]
    }
   ],
   "source": [
    "hloss = HLoss()\n",
    "batch_h = hloss(pi_x)\n",
    "\n",
    "print(batch_h.size(), \"\\n\", batch_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3]) \n",
      " tensor([[0.3516, 0.4421, 0.2063],\n",
      "        [0.1354, 0.3675, 0.4971]])\n"
     ]
    }
   ],
   "source": [
    "softmax_pi = torch.nn.functional.softmax(pi_x, dim=1)\n",
    "print(softmax_pi.size(), \"\\n\", softmax_pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3]) \n",
      " tensor([[-1.0452, -0.8162, -1.5785],\n",
      "        [-1.9996, -1.0011, -0.6989]])\n"
     ]
    }
   ],
   "source": [
    "log_softmax_pi = torch.nn.functional.log_softmax(pi_x, dim=1)\n",
    "print(log_softmax_pi.size(), \"\\n\", log_softmax_pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3]) n tensor([[-0.3675, -0.3609, -0.3256],\n",
      "        [-0.2707, -0.3679, -0.3474]])\n"
     ]
    }
   ],
   "source": [
    "h = softmax_pi * log_softmax_pi\n",
    "print(h.size(), \"n\", h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2]) n tensor([-1.0540, -0.9860])\n"
     ]
    }
   ],
   "source": [
    "h = torch.sum(h, dim=1)\n",
    "print(h.size(), \"n\", h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([]) \n",
      " tensor(-1.0200)\n"
     ]
    }
   ],
   "source": [
    "final_h_loss = torch.mean(h)\n",
    "print(final_h_loss.size(), \"\\n\", final_h_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([]) \n",
      " tensor(14.0728, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "unlabelled_loss = final_weighted_loss + final_h_loss\n",
    "print_tensor(unlabelled_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Labelled case\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assume `batch_size = 2`, `num_latent_dims=4` and `num_classes=3`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "num_latent_dims = 4\n",
    "num_classes = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4]) \n",
      " tensor([[-1.0374,  1.0577,  1.8441, -1.4078],\n",
      "        [ 0.5333, -1.4268, -0.3109,  0.9253]])\n"
     ]
    }
   ],
   "source": [
    "z_prime = torch.randn(batch_size, num_latent_dims)\n",
    "print_tensor(z_prime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2]) \n",
      " tensor([1, 2])\n"
     ]
    }
   ],
   "source": [
    "labels = torch.tensor([1,2])\n",
    "print_tensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3]) \n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "y_onehot = torch.zeros(batch_size, num_classes)\n",
    "print_tensor(y_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3]) \n",
      " tensor([[0., 1., 0.],\n",
      "        [0., 0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "y_onehot = y_onehot.scatter(1, labels.reshape(-1,1), 1)\n",
    "print_tensor(y_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 7]) \n",
      " tensor([[-1.0374,  1.0577,  1.8441, -1.4078,  0.0000,  1.0000,  0.0000],\n",
      "        [ 0.5333, -1.4268, -0.3109,  0.9253,  0.0000,  0.0000,  1.0000]])\n"
     ]
    }
   ],
   "source": [
    "z_prime_y = torch.cat((z_prime, y_onehot), dim=1)\n",
    "print_tensor(z_prime_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = torch.nn.Linear(num_latent_dims+num_classes, num_latent_dims)\n",
    "logvar = torch.nn.Linear(num_latent_dims, num_latent_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4]) \n",
      " tensor([[ 0.7054, -0.2334, -0.5250,  1.4733],\n",
      "        [-0.4138,  0.2683,  0.2979, -0.4144]], grad_fn=<AddmmBackward>)\n",
      "torch.Size([2, 4]) \n",
      " tensor([[ 1.6079,  0.0586,  0.1093,  0.6846],\n",
      "        [ 0.1963, -0.5290, -0.3938, -0.2295]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "z_mu = mu(z_prime_y)\n",
    "z_logvar = logvar(z_prime)\n",
    "\n",
    "print(z_mu.size(), \"\\n\", z_mu)\n",
    "print(z_logvar.size(), \"\\n\", z_logvar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4]) \n",
      " tensor([[ 0.9510,  1.2275,  0.0739,  0.6057],\n",
      "        [-0.8320,  0.4875,  1.2786, -0.2984]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Reparameterization trick\n",
    "std = z_logvar.mul(0.5).exp()\n",
    "eps = std.new(std.size()).normal_()\n",
    "z = eps.mul(std).add(z_mu)\n",
    "\n",
    "print_tensor(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.cat((z, y_onehot), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 7]) \n",
      " tensor([[ 0.9510,  1.2275,  0.0739,  0.6057,  0.0000,  1.0000,  0.0000],\n",
      "        [-0.8320,  0.4875,  1.2786, -0.2984,  0.0000,  0.0000,  1.0000]],\n",
      "       grad_fn=<CatBackward>)\n"
     ]
    }
   ],
   "source": [
    "print_tensor(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the loss for the labelled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2]) \n",
      " tensor([2.8445, 0.3676], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "batch_kl_loss = -0.5 * torch.sum(1 + z_logvar - z_mu.pow(2) - z_logvar.exp(), dim=1)\n",
    "print_tensor(batch_kl_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([]) \n",
      " tensor(34.1392, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "batch_mse_loss = torch.nn.MSELoss(reduction=\"sum\")(torch.randn(2,7), z)\n",
    "print_tensor(batch_mse_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([]) \n",
      " tensor(20.2816, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "mse_loss = batch_mse_loss/batch_size\n",
    "kl_loss = torch.sum(batch_kl_loss, dim=0)\n",
    "\n",
    "vae_loss = mse_loss + kl_loss\n",
    "print_tensor(vae_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3]) \n",
      " tensor([[-1.4511,  0.7269,  2.6331],\n",
      "        [ 1.0599, -0.1613,  0.3179]])\n"
     ]
    }
   ],
   "source": [
    "pi_x = torch.randn(batch_size, num_classes)\n",
    "print_tensor(pi_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2]) \n",
      " tensor([2.0593, 1.3136])\n"
     ]
    }
   ],
   "source": [
    "ce_loss = torch.nn.CrossEntropyLoss(reduction=\"none\")(pi_x, labels)\n",
    "print_tensor(ce_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([]) \n",
      " tensor(1.6864)\n"
     ]
    }
   ],
   "source": [
    "ce_loss = torch.nn.CrossEntropyLoss()(pi_x, labels)\n",
    "print_tensor(ce_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([]) \n",
      " tensor(10.4115, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "loss = vae_loss + ce_loss\n",
    "print_tensor(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Miscellanous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 1]) \n",
      " tensor([[[-1.7813],\n",
      "         [ 0.7235],\n",
      "         [ 0.5495]],\n",
      "\n",
      "        [[-1.9287],\n",
      "         [ 2.2646],\n",
      "         [ 1.3902]],\n",
      "\n",
      "        [[ 0.3168],\n",
      "         [ 0.5489],\n",
      "         [-0.7260]],\n",
      "\n",
      "        [[ 0.0548],\n",
      "         [ 1.0034],\n",
      "         [-0.7268]]])\n"
     ]
    }
   ],
   "source": [
    "batch_mse = torch.randn((4,3,1))\n",
    "print_tensor(batch_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1]) \n",
      " tensor([[-0.1695],\n",
      "        [ 0.5753],\n",
      "        [ 0.0466],\n",
      "        [ 0.1105]])\n"
     ]
    }
   ],
   "source": [
    "mse = torch.mean(batch_mse, dim=1)\n",
    "print_tensor(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([]) \n",
      " tensor(0.1407)\n"
     ]
    }
   ],
   "source": [
    "mse = torch.mean(mse)\n",
    "print_tensor(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
